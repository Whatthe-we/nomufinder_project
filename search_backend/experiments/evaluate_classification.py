import json
import sys
import csv
import os
from openai import OpenAI
from dotenv import load_dotenv
from sklearn.metrics import classification_report, accuracy_score

# classifier.py ìƒëŒ€ê²½ë¡œ import í—ˆìš©
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from classifier import (
    categories,
    clean_category_output,
    classify_text_with_openai
)

# === ëª¨ë¸ ì„¸íŒ… ===
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
classify_text_with_openai.__globals__["client"] = client

# === í‰ê°€ ë°ì´í„° ===
def generate_eval_dataset(path="fastapi_server/experiments/evaluation_dataset.json"):
    dataset = [
        {"text": "ì›”ê¸‰ì´ ê³„ì† ì§€ì—°ë˜ê³  ìˆì–´ìš”", "label": "ì„ê¸ˆ/í‡´ì§ê¸ˆ"},
        {"text": "ê³„ì•½ì„œë„ ì•ˆ ì“°ê³  ì¼ë§Œ ì‹œì¼œìš”", "label": "ê·¼ë¡œê³„ì•½"},
        {"text": "ì•¼ê·¼ ìˆ˜ë‹¹ ì•ˆ ì£¼ëŠ” ê±´ ë¶ˆë²• ì•„ë‹Œê°€ìš”?", "label": "ê·¼ë¬´ì¡°ê±´"},
        {"text": "ë…¸ì¡° ë§Œë“¤ì—ˆë‹¤ê³  ê°‘ìê¸° ë‹¤ë¥¸ ë¶€ì„œë¡œ ì´ë™í–ˆì–´ìš”", "label": "ë…¸ë™ì¡°í•©"},
        {"text": "ì¶œê·¼ ì¤‘ì— êµí†µì‚¬ê³  ë‚¬ëŠ”ë° ì¹˜ë£Œë¹„ë¥¼ ì œê°€ ë¶€ë‹´í•´ì•¼ í•˜ë‚˜ìš”?", "label": "ì‚°ì—…ì¬í•´"},
        {"text": "ì„±í¬ë¡± ì‹ ê³ í–ˆë”ë‹ˆ íŒ€ì¥ì´ ë” ì‹¬í•˜ê²Œ ê´´ë¡­í˜€ìš”", "label": "ì§ì¥ë‚´ì„±í¬ë¡±"},
        {"text": "ì—…ë¬´ íƒœë„ ë¬¸ì œë¡œ ê²½ê³  ë¨¹ì—ˆì–´ìš”", "label": "ë¶€ë‹¹ì§•ê³„"},
        {"text": "ì´ìœ  ì—†ì´ ê°‘ìê¸° ë‚´ì¼ë¶€í„° ì¶œê·¼í•˜ì§€ ë§ë˜ìš”", "label": "ë¶€ë‹¹í•´ê³ "},
        {"text": "ë¹„ì •ê·œì§ì´ë¼ëŠ” ì´ìœ ë¡œ ì—°ì°¨ë„ ëª» ì¨ìš”", "label": "ì§ì¥ë‚´ì°¨ë³„"},
        {"text": "ì…ì‚¬í•œ ì§€ í•œ ë‹¬ ë§Œì— ìˆ˜ìŠµì´ë¼ê³  ì˜ë ¸ì–´ìš”", "label": "ë¶€ë‹¹í•´ê³ "},
        {"text": "ìƒì‚¬ê°€ ì™¸ëª¨ì— ëŒ€í•´ ê³„ì† ë§í•´ìš”", "label": "ì§ì¥ë‚´ì„±í¬ë¡±"},
        {"text": "ì¼ì„ ë„ˆë¬´ ë§ì´ ì‹œí‚¤ê³  í˜¼ìì„œ ê°ë‹¹ì´ ì•ˆ ë¼ìš”", "label": "ì§ì¥ë‚´ê´´ë¡­í˜"},
        {"text": "ìˆ˜ë‹¹ì„ ì•ˆ ì£¼ëŠ” ê±´ ë¬¼ë¡ ì´ê³ , ì£¼íœ´ìˆ˜ë‹¹ë„ ëª°ë¼ìš”", "label": "ê·¼ë¬´ì¡°ê±´"},
        {"text": "ì¶œì‚°íœ´ê°€ ë‹¤ë…€ì˜¨ ë’¤ ë¶€ì„œê°€ ë°”ë€Œì—ˆì–´ìš”", "label": "ì§ì¥ë‚´ì°¨ë³„"},
        {"text": "í‡´ì§ê¸ˆì´ ì•ˆ ë“¤ì–´ì™”ëŠ”ë° ë¬¼ì–´ë³´ë‹ˆ ëª¨ë¥¸ë‹¤ê³  í•´ìš”", "label": "ì„ê¸ˆ/í‡´ì§ê¸ˆ"},
        {"text": "ì§•ê³„ìœ„ì›íšŒ ì—†ì´ ë°”ë¡œ ì •ì§ë‹¹í–ˆì–´ìš”", "label": "ë¶€ë‹¹ì§•ê³„"},
        {"text": "ê³„ì•½ì§ì¸ë° ê³„ì•½ ì—°ì¥ì„ í•´ì£¼ì§€ ì•Šê² ëŒ€ìš”", "label": "ê·¼ë¡œê³„ì•½"},
        {"text": "ì£¼ë§ë§ˆë‹¤ ë‚˜ì™€ì„œ ì¼í•˜ëŠ”ë° ìˆ˜ë‹¹ë„ ì—†ì–´ìš”", "label": "ê·¼ë¬´ì¡°ê±´"},
        {"text": "ë…¸ì¡°ì— ê°€ì…í–ˆë”ë‹ˆ íšŒì‹ì—ì„œë„ ë”°ëŒë¦¼ë‹¹í•´ìš”", "label": "ë…¸ë™ì¡°í•©"},
        {"text": "ì¶œê·¼ê¸¸ ì‚¬ê³ ì¸ë° ì‚°ì¬ ì²˜ë¦¬ ëª» í•´ì¤€ëŒ€ìš”", "label": "ì‚°ì—…ì¬í•´"}
    ]
    with open(path, "w", encoding="utf-8") as f:
        json.dump(dataset, f, ensure_ascii=False, indent=2)
    print(f"âœ… í‰ê°€ì…‹ ì €ì¥ë¨: {path}")
    return dataset

# === Zero-shot ë¶„ë¥˜ í•¨ìˆ˜ ===
def classify_text_zeroshot(user_input: str) -> str:
    prompt = f"""
ë‹¹ì‹ ì€ ì•„ë˜ ë¬¸ì¥ì„ ë¶„ë¥˜í•˜ëŠ” AIì…ë‹ˆë‹¤.
ë¬¸ì¥ì„ ì•„ë˜ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:

- {', '.join(categories)}

ë¬¸ì¥: {user_input}
ì¹´í…Œê³ ë¦¬:"""
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=50,
        )
        result = response.choices[0].message.content.strip()
        return clean_category_output(result)
    except Exception as e:
        print("âŒ Zero-shot ì˜¤ë¥˜:", e)
        return "ë¶„ë¥˜ ì‹¤íŒ¨"

# === ì˜¤ë‹µ ë¡œê·¸ ì €ì¥ ===
def save_misclassified_log(name, y_true, y_pred, dataset, path_prefix="fastapi_server/experiments"):
    misclassified = []
    for i, (true, pred) in enumerate(zip(y_true, y_pred)):
        if true != pred:
            misclassified.append({
                "model": name,
                "text": dataset[i]["text"],
                "true_label": true,
                "predicted_label": pred
            })

    if not misclassified:
        print(f"âœ… [{name}] ëª¨ë“  ì˜ˆì¸¡ì´ ì •ë‹µì…ë‹ˆë‹¤!")
        return

    full_path = os.path.join(path_prefix, f"misclassified_{name.lower().replace('-', '_')}.json")
    with open(full_path, "w", encoding="utf-8") as f:
        json.dump(misclassified, f, ensure_ascii=False, indent=2)
    print(f"â— ì˜¤ë‹µ ë¡œê·¸ ì €ì¥ë¨: {full_path}")

# === í‰ê°€ í•¨ìˆ˜ ===
def evaluate_model(name, classify_fn, dataset):
    y_true, y_pred = [], []
    for item in dataset:
        text, label = item["text"], item["label"]
        pred = classify_fn(text)
        y_true.append(label)
        y_pred.append(pred)
        print(f"[{name}] {text}\nğŸ‘‰ ì˜ˆì¸¡: {pred}, âœ… ì •ë‹µ: {label}\n")

    acc = accuracy_score(y_true, y_pred)
    report = classification_report(y_true, y_pred, labels=categories, zero_division=0, output_dict=True)

    # ì˜¤ë‹µ ì €ì¥
    save_misclassified_log(name, y_true, y_pred, dataset)

    return {
        "name": name,
        "accuracy": acc,
        "macro_f1": report["macro avg"]["f1-score"],
        "micro_f1": report["accuracy"]
    }

# === ê²°ê³¼ CSV ì €ì¥ ===
def save_results_csv(results: list[dict], path="fastapi_server/experiments/evaluation_result.csv"):
    with open(path, mode="w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=["name", "accuracy", "macro_f1", "micro_f1"])
        writer.writeheader()
        for row in results:
            writer.writerow(row)
    print(f"ğŸ“„ ì„±ëŠ¥ ê²°ê³¼ ì €ì¥ë¨: {path}")

# === ë©”ì¸ ì‹¤í–‰ ===
if __name__ == "__main__":
    print("ğŸš€ í‰ê°€ ì‹œì‘")
    dataset = generate_eval_dataset()

    # Few-shot
    few_result = evaluate_model("Few-shot", classify_text_with_openai, dataset)

    # Zero-shot
    zero_result = evaluate_model("Zero-shot", classify_text_zeroshot, dataset)

    # ì €ì¥
    save_results_csv([few_result, zero_result])