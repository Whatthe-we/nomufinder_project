# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f3roGgMbU7l_i9cVEsNXsFJlyItZCFK8

--- 중요: 경로 설정 ---

이 경로들은 API 서버가 실행되는 환경 기준으로 설정해야 합니다.

Google Drive에서 파일을 미리 다운로드 받아 이 경로에 위치시켜야 합니다.

RESULT_DIR = "./nomu_rag_result" # 예시: 서버의 로컬 경로

FAISS_INDEX_PATH = os.path.join(RESULT_DIR, "faiss_index_nomu_final")

BM25_DATA_PATH = os.path.join(RESULT_DIR, "split_texts_for_bm25.pkl")

Google Drive 경로 (참고용, 실제 로드는 서버 로컬 경로에서)

GDRIVE_RESULT_DIR = "/content/drive/MyDrive/nomu_rag_result"

# === 설정값 ===
FAISS_INDEX_PATH = "faiss_index_nomu_final" # 로컬 인덱스 경로

EMBEDDING_MODEL_NAME = "text-embedding-ada-002" # 임베딩 모델

LLM_MODEL_NAME = "gpt-4.1-nano" # 사용할 LLM 모델 (또는 gpt-3.5-turbo 등)

FIREBASE_DB_URL = os.getenv("FIREBASE_DATABASE_URL") # .env 파일에

FIREBASE_DATABASE_URL=https://<your-project-id>-default-rtdb.firebaseio.com/ 형태

FIREBASE_SERVICE_ACCOUNT_KEY = "serviceAccountKey.json" # 서비스 계정 키 파일 경로

FIREBASE_QUESTIONS_PATH = "/chat_questions" # 질문 감지 경로

FIREBASE_ANSWERS_PATH = "/chat_answers"     # 답변 저장 경로
"""

# main.py (OpenAI Embedding 사용 버전)
import uvicorn
from fastapi import FastAPI, HTTPException
import os
import threading
import time
import traceback
from dotenv import load_dotenv
import pickle

# --- Firebase Admin SDK ---
import firebase_admin
from firebase_admin import credentials, db

# --- LangChain & RAG 관련 ---
from langchain_openai import ChatOpenAI, OpenAIEmbeddings # <<< OpenAIEmbeddings 추가
# from langchain_community.embeddings import HuggingFaceEmbeddings # <<< HuggingFace 제거 또는 주석 처리
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever
# import torch # OpenAI Embedding 사용 시 torch 직접 필요 없음 (FAISS 내부 의존성 가능성은 있음)

# --- .env 파일 로드 ---
load_dotenv()

# === 전역 변수 ===
qa_chain = None
firebase_app = None
is_initialized = False

# === 설정값 ===
FAISS_INDEX_PATH = "faiss_index_nomu_final"
BM25_DATA_PATH = "split_texts_for_bm25.pkl"
FIREBASE_SERVICE_ACCOUNT_KEY = "serviceAccountKey.json"

# ===> 모델 설정 수정 <===
EMBEDDING_MODEL_NAME = "text-embedding-ada-002" # OpenAI 임베딩 모델
LLM_MODEL_NAME = "gpt-4.1-nano"                 # 사용할 LLM 모델
# =====================

# Firebase 설정 (환경 변수에서 로드)
FIREBASE_DB_URL = os.getenv("FIREBASE_DATABASE_URL")
if not FIREBASE_DB_URL:
    print("!! [치명적 오류] .env 파일에서 FIREBASE_DATABASE_URL을 찾을 수 없습니다. 앱 실행 불가.")

# Firebase 경로 설정
FIREBASE_QUESTIONS_PATH = "/chat_questions"
FIREBASE_ANSWERS_PATH = "/chat_answers"

# Retriever 설정값
FAISS_K = 6
BM25_K = 6
ENSEMBLE_WEIGHTS = [0.7, 0.3] # BM25=0.7, FAISS=0.3

# === FastAPI 앱 인스턴스 ===
app = FastAPI()

# === RAG 파이프라인 초기화 함수 ===
def initialize_rag():
    global qa_chain, is_initialized
    if is_initialized:
        print("[정보] RAG 파이프라인 이미 초기화됨.")
        return

    print("--- RAG 파이프라인 초기화 시작 ---")
    vectorstore = None
    split_texts = None
    retriever = None
    llm = None
    embeddings = None # OpenAIEmbeddings 객체를 담을 변수

    try:
        # 1. OpenAI API 키 확인 (LLM 및 Embedding 모두 사용)
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            raise ValueError("환경 변수에서 OPENAI_API_KEY를 찾을 수 없습니다.")

        # ===> 1. 임베딩 모델 로드 (OpenAIEmbeddings 사용) <===
        print(f"임베딩 모델 로딩 중 ({EMBEDDING_MODEL_NAME})...")
        embeddings = OpenAIEmbeddings(
            model=EMBEDDING_MODEL_NAME,
            openai_api_key=openai_api_key
            # 필요시 추가 파라미터 설정 (e.g., chunk_size for batching)
        )
        print("OpenAI 임베딩 모델 준비 완료.")
        # =============================================

        # ===> 2. FAISS 인덱스 로드 <===
        # !! 중요 !! 이 인덱스는 반드시 OpenAIEmbeddings(text-embedding-ada-002)로
        # !!      생성된 것이어야 합니다 !!
        print(f"FAISS 인덱스 로딩 중 ({FAISS_INDEX_PATH})...")
        if not os.path.isdir(FAISS_INDEX_PATH):
            raise FileNotFoundError(f"FAISS 인덱스 폴더({FAISS_INDEX_PATH})를 찾을 수 없습니다. OpenAI 임베딩으로 인덱스를 다시 생성해야 합니다.")
        try:
            vectorstore = FAISS.load_local(
                FAISS_INDEX_PATH,
                embeddings, # OpenAIEmbeddings 객체 전달
                allow_dangerous_deserialization=True
            )
            print(f"FAISS 인덱스 로드 완료 ({vectorstore.index.ntotal} 벡터).")
            print("   ⚠️ 경고: 로드된 FAISS 인덱스가 반드시 OpenAI 임베딩 모델로 생성되었는지 확인하세요!")
        except Exception as faiss_load_e:
             print(f"!! [오류] FAISS 인덱스 로드 실패: {faiss_load_e}")
             print("   인덱스가 손상되었거나, 잘못된 임베딩 모델로 생성되었을 수 있습니다.")
             print("   OpenAI 임베딩 모델로 FAISS 인덱스를 다시 생성해야 합니다.")
             raise faiss_load_e # 초기화 중단

        # ==========================

        # 2.5 BM25용 데이터 로드 (기존과 동일)
        print(f"BM25용 데이터 로딩 중 ({BM25_DATA_PATH})...")
        if not os.path.exists(BM25_DATA_PATH):
             print(f"⚠️ 경고: BM25 데이터 파일({BM25_DATA_PATH}) 없음. FAISS만 사용.")
             split_texts = None
        else:
             try:
                 with open(BM25_DATA_PATH, 'rb') as f:
                     split_texts = pickle.load(f)
                 print(f"BM25용 데이터 로드 완료 ({len(split_texts)}개 청크).")
             except Exception as e_pickle:
                 print(f"!! [오류] BM25 데이터 로드 실패: {e_pickle}")
                 split_texts = None

        # 3. Retriever 설정 (하이브리드 적용 - 기존과 동일)
        print("Retriever 설정 중...")
        if vectorstore:
            faiss_retriever = vectorstore.as_retriever(search_kwargs={'k': FAISS_K})
            print(f"- Dense Retriever (FAISS) 설정 완료 (k={FAISS_K}).")
            if split_texts:
                try:
                    bm25_retriever = BM25Retriever.from_documents(split_texts)
                    bm25_retriever.k = BM25_K
                    print(f"- Sparse Retriever (BM25) 설정 완료 (k={BM25_K}).")
                    ensemble_retriever = EnsembleRetriever(
                        retrievers=[bm25_retriever, faiss_retriever],
                        weights=ENSEMBLE_WEIGHTS
                    )
                    retriever = ensemble_retriever
                    print(f"- Ensemble Retriever 설정 완료 (Weights: BM25={ENSEMBLE_WEIGHTS[0]}, FAISS={ENSEMBLE_WEIGHTS[1]}).")
                except Exception as e_ensemble:
                    print(f"!! BM25/Ensemble 설정 실패: {e_ensemble}. FAISS Retriever만 사용.")
                    retriever = faiss_retriever
            else:
                print("⚠️ BM25 데이터 없어 Dense Retriever(FAISS)만 사용합니다.")
                retriever = faiss_retriever
        else:
            raise ValueError("FAISS VectorStore 로드 실패. Retriever 설정 불가.")

        # 4. LLM 로드 (OpenAI - 기존과 동일)
        print(f"LLM 로딩 중 ({LLM_MODEL_NAME})...")
        llm = ChatOpenAI(model_name=LLM_MODEL_NAME, temperature=0.1, openai_api_key=openai_api_key)
        print("LLM 로드 완료.")

        # 5. RAG Chain 구축 (기존과 동일)
        print("RAG Chain 구축 중...")
        template = """주어진 '컨텍스트' 정보만을 사용하여 '질문'에 답변하십시오. 한국어로 답변해주세요.
        컨텍스트에 답변이 없으면 "제공된 문서 내용만으로는 답변할 수 없습니다."라고 답변하세요.
        컨텍스트: {context}
        질문: {question}
        답변:"""
        QA_CHAIN_PROMPT = PromptTemplate.from_template(template)

        if not retriever: raise ValueError("Retriever 객체가 성공적으로 생성되지 않았습니다.")
        if not llm: raise ValueError("LLM 객체가 성공적으로 생성되지 않았습니다.")

        global qa_chain # 전역 변수 할당 명시
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True,
            chain_type_kwargs={"prompt": QA_CHAIN_PROMPT}
        )
        print("[성공] RAG 파이프라인 초기화 완료.")
        is_initialized = True

    except Exception as e:
        print(f"!! [오류] RAG 파이프라인 초기화 실패: {e}")
        traceback.print_exc()
        qa_chain = None
        is_initialized = False

# === Firebase 리스너 콜백 함수 ===
# (기존 코드와 동일)
def firebase_listener_callback(event):
    global qa_chain # 전역 qa_chain 사용 명시
    print(f"\n--- Firebase 이벤트 감지 ---")
    print(f"  이벤트 타입: {event.event_type}, 경로: {event.path}")

    if event.event_type == 'put' and event.data and event.path.startswith(f"{FIREBASE_QUESTIONS_PATH}/"):
        question_id = event.path.split('/')[-1]
        question_data = event.data

        if isinstance(question_data, dict) and 'query' in question_data:
            query = question_data.get('query', '').strip()
            if not query:
                print("  [정보] 질문 내용(query)이 비어있어 처리하지 않음.")
                return

            print(f"  처리할 질문 ID: {question_id}, 질문 내용: {query[:50]}...")

            if not is_initialized or not qa_chain: # 초기화 완료 및 qa_chain 유효성 검사
                 print("!! RAG 파이프라인이 초기화되지 않아 답변 생성 불가.")
                 # 오류 상황 Firebase에 기록
                 try:
                     error_ref = db.reference(f"{FIREBASE_ANSWERS_PATH}/{question_id}")
                     error_ref.set({
                         'error': 'RAG backend not initialized or QA chain is missing.',
                         'timestamp': int(time.time())
                     })
                 except Exception as db_err:
                     print(f"!! Firebase에 오류 기록 실패: {db_err}")
                 return # 처리 중단

            # RAG 처리
            try:
                print("  RAG 답변 생성 시도...")
                start_time = time.time()
                result = qa_chain.invoke({"query": query})
                end_time = time.time()
                answer = result.get('result', '오류: 답변 생성 실패')
                print(f"  답변 생성 완료 ({end_time - start_time:.2f}초). 답변: {answer[:50]}...")

                source_info = []
                source_documents = result.get('source_documents', [])
                if source_documents:
                    source_info = [
                        {"content": doc.page_content[:100]+"...", "metadata": {k: str(v)[:50] for k, v in doc.metadata.items()}}
                        for doc in source_documents[:2]
                    ]

                answer_ref = db.reference(f"{FIREBASE_ANSWERS_PATH}/{question_id}")
                answer_data = {'answer': answer, 'timestamp': int(time.time()), 'sources': source_info}
                answer_ref.set(answer_data)
                print(f"  Firebase '{FIREBASE_ANSWERS_PATH}/{question_id}' 경로에 답변 저장 완료.")

            except Exception as e:
                print(f"!! RAG 처리 또는 Firebase 쓰기 오류: {e}")
                traceback.print_exc()
                try:
                     error_ref = db.reference(f"{FIREBASE_ANSWERS_PATH}/{question_id}")
                     error_ref.set({'error': f"{type(e).__name__}: {str(e)[:200]}", 'timestamp': int(time.time())})
                except Exception as db_err: print(f"!! Firebase에 오류 기록 실패: {db_err}")
        else: print(f"  [정보] 처리할 형식이 아니거나 'query' 필드 없음: {type(question_data)}")
    elif event.path == "/" and event.data is not None: print(f"  [정보] 루트 경로('/') 직접 쓰기 이벤트 감지됨. 무시.")
    elif event.data is None: print(f"  [정보] 데이터 삭제 이벤트 감지 (경로: {event.path}). 별도 처리 없음.")
    else: print(f"  [정보] 처리하지 않는 이벤트 타입 또는 경로: {event.event_type}, {event.path}")


# === FastAPI 시작 이벤트 핸들러 ===
@app.on_event("startup")
async def startup_event_handler():
    global firebase_app
    print("--- FastAPI Application Startup ---")

    initialize_rag() # RAG 파이프라인 초기화 먼저 시도

    if not FIREBASE_DB_URL: print("!! [치명적 오류] FIREBASE_DATABASE_URL 환경 변수가 설정되지 않았습니다. Firebase 리스너 시작 불가."); return
    if not os.path.exists(FIREBASE_SERVICE_ACCOUNT_KEY): print(f"!! [치명적 오류] Firebase 서비스 계정 키 파일({FIREBASE_SERVICE_ACCOUNT_KEY})을 찾을 수 없습니다. Firebase 리스너 시작 불가."); return

    try:
        cred = credentials.Certificate(FIREBASE_SERVICE_ACCOUNT_KEY)
        if not firebase_admin._apps:
             firebase_app = firebase_admin.initialize_app(cred, {'databaseURL': FIREBASE_DB_URL})
             print("[성공] Firebase Admin SDK 초기화 완료.")
        else:
             firebase_app = firebase_admin.get_app()
             print("[정보] Firebase Admin SDK 이미 초기화됨.")

        print(f"Firebase 경로 '{FIREBASE_QUESTIONS_PATH}' 리스닝 시작...")
        listener_thread = threading.Thread(
            target=db.reference(FIREBASE_QUESTIONS_PATH).listen,
            args=(firebase_listener_callback,),
            daemon=True
        )
        listener_thread.start()
        print("[정보] Firebase 리스너 스레드 시작됨.")

    except Exception as e:
        print(f"!! [오류] Firebase 초기화 또는 리스너 시작 실패: {e}")
        traceback.print_exc()

# === 기본 루트 엔드포인트 ===
@app.get("/")
async def read_root():
    return {"message": "Nomu RAG Backend is running!", "initialized": is_initialized}

# === 로컬 실행용 코드 ===
if __name__ == "__main__":
    print("--- 로컬 서버 시작 (uvicorn) ---")
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)