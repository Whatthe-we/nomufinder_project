# main.py (OpenAI Embedding ì‚¬ìš© ë²„ì „)
import uvicorn
from fastapi import FastAPI, HTTPException
import os
import threading
import time
import traceback
from dotenv import load_dotenv
import pickle
import json

# --- Firebase Admin SDK ---
import firebase_admin
from firebase_admin import credentials, db

# --- LangChain & RAG ê´€ë ¨ ---
from langchain_openai import ChatOpenAI, OpenAIEmbeddings # <<< OpenAIEmbeddings ì¶”ê°€
# from langchain_community.embeddings import HuggingFaceEmbeddings # <<< HuggingFace ì œê±° ë˜ëŠ” ì£¼ì„ ì²˜ë¦¬
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever
# import torch # OpenAI Embedding ì‚¬ìš© ì‹œ torch ì§ì ‘ í•„ìš” ì—†ìŒ (FAISS ë‚´ë¶€ ì˜ì¡´ì„± ê°€ëŠ¥ì„±ì€ ìˆìŒ)

# --- .env íŒŒì¼ ë¡œë“œ ---
load_dotenv()

# === ì „ì—­ ë³€ìˆ˜ ===
qa_chain = None
firebase_app = None
is_initialized = False
processed_question_ids = set()  # âœ… ì´ë¯¸ ì²˜ë¦¬í•œ ì§ˆë¬¸ ID ì €ì¥
startup_time = int(time.time())  # âœ… ì„œë²„ ì‹œì‘ ì‹œê°„ ê¸°ë¡

# === ì„¤ì •ê°’ ===
FAISS_INDEX_PATH = "faiss_index_nomu_final"
BM25_DATA_PATH = "split_texts_for_bm25.pkl"
FIREBASE_SERVICE_ACCOUNT_KEY = "serviceAccountKey.json"

# ===> ëª¨ë¸ ì„¤ì • ìˆ˜ì • <===
EMBEDDING_MODEL_NAME = "text-embedding-3-large" # OpenAI ì„ë² ë”© ëª¨ë¸
LLM_MODEL_NAME = "gpt-4.1"                      # âœ…Â ì‚¬ìš©í•  LLM ëª¨ë¸
# =====================

# Firebase ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
FIREBASE_DB_URL = os.getenv("FIREBASE_DATABASE_URL")
if not FIREBASE_DB_URL:
    print("!! [ì¹˜ëª…ì  ì˜¤ë¥˜] .env íŒŒì¼ì—ì„œ FIREBASE_DATABASE_URLì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì•± ì‹¤í–‰ ë¶ˆê°€.")
FIREBASE_QUESTIONS_PATH = "/chat_questions"
FIREBASE_ANSWERS_PATH = "/chat_answers"
QUESTION_LOG_PATH = "chat_log.json"

# Retriever ì„¤ì •ê°’
FAISS_K = 6
BM25_K = 6
ENSEMBLE_WEIGHTS = [0.7, 0.3] # BM25=0.7, FAISS=0.3

# === FastAPI ì•± ì¸ìŠ¤í„´ìŠ¤ ===
app = FastAPI()

# === âœ… ì§ˆë¬¸ ì¬ì²˜ë¦¬ ===
PROCESSED_IDS_JSON_PATH = "processed_ids.json"
PROCESSED_IDS_BACKUP_PATH = "processed_ids_backup.json"
MAX_PROCESSED_IDS = 100

def load_processed_ids():
    global processed_question_ids
    if os.path.exists(PROCESSED_IDS_JSON_PATH):
        with open(PROCESSED_IDS_JSON_PATH, "r", encoding="utf-8") as f:
            processed_question_ids = set(json.load(f))
        print(f"âœ… ì²˜ë¦¬ëœ ID {len(processed_question_ids)}ê°œ ë¡œë“œë¨")
    else:
        processed_question_ids = set()

def save_processed_id(question_id):
    global processed_question_ids

    processed_question_ids.add(question_id)
    # ğŸ”„ ìµœëŒ€ ê°œìˆ˜ ì´ˆê³¼ ì‹œ ë°±ì—… + ì •ë¦¬
    if len(processed_question_ids) > MAX_PROCESSED_IDS:
        print(f"ğŸ“¦ ìµœëŒ€ {MAX_PROCESSED_IDS}ê°œ ì´ˆê³¼ë¨ â†’ ë°±ì—… ë° ì •ë¦¬ ìˆ˜í–‰")
        all_ids = sorted(list(processed_question_ids))
        # âœ… ë°±ì—… (ì „ì²´ ì €ì¥)
        with open(PROCESSED_IDS_BACKUP_PATH, "w", encoding="utf-8") as f_backup:
            json.dump(all_ids, f_backup, ensure_ascii=False, indent=2)
        # ìµœì‹  MAX ê°œìˆ˜ë§Œ ìœ ì§€
        processed_question_ids = set(all_ids[-MAX_PROCESSED_IDS:])
    # âœï¸ ìµœì¢… ì €ì¥
    with open(PROCESSED_IDS_JSON_PATH, "w", encoding="utf-8") as f:
        json.dump(list(processed_question_ids), f, ensure_ascii=False, indent=2)

def log_question_answer_pair(question_id, question, answer):
    log_entry = {
        "id": question_id,
        "question": question,
        "answer": answer,
        "timestamp": int(time.time())
    }
    if os.path.exists(QUESTION_LOG_PATH):
        with open(QUESTION_LOG_PATH, "r", encoding="utf-8") as f:
            logs = json.load(f)
    else:
        logs = []
    logs.append(log_entry)
    with open(QUESTION_LOG_PATH, "w", encoding="utf-8") as f:
        json.dump(logs, f, ensure_ascii=False, indent=2)

# === RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” í•¨ìˆ˜ ===
def initialize_rag():
    global qa_chain, is_initialized
    if is_initialized:
        print("[ì •ë³´] RAG íŒŒì´í”„ë¼ì¸ ì´ë¯¸ ì´ˆê¸°í™”ë¨.")
        return

    print("--- RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹œì‘ ---")
    vectorstore = None
    split_texts = None
    retriever = None
    llm = None
    embeddings = None # OpenAIEmbeddings ê°ì²´ë¥¼ ë‹´ì„ ë³€ìˆ˜

    try:
        # 1. OpenAI API í‚¤ í™•ì¸ (LLM ë° Embedding ëª¨ë‘ ì‚¬ìš©)
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            raise ValueError("í™˜ê²½ ë³€ìˆ˜ì—ì„œ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ===> 1. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (OpenAIEmbeddings ì‚¬ìš©) <===
        print(f"ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘ ({EMBEDDING_MODEL_NAME})...")
        embeddings = OpenAIEmbeddings(
            model=EMBEDDING_MODEL_NAME,
            openai_api_key=openai_api_key
            # í•„ìš”ì‹œ ì¶”ê°€ íŒŒë¼ë¯¸í„° ì„¤ì • (e.g., chunk_size for batching)
        )
        print("OpenAI ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ.")
        # =============================================

        # ===> 2. FAISS ì¸ë±ìŠ¤ ë¡œë“œ <===
        # !! ì¤‘ìš” !! ì´ ì¸ë±ìŠ¤ëŠ” ë°˜ë“œì‹œ OpenAIEmbeddings(text-embedding-ada-002)ë¡œ
        # !!      ìƒì„±ëœ ê²ƒì´ì–´ì•¼ í•©ë‹ˆë‹¤ !!
        print(f"FAISS ì¸ë±ìŠ¤ ë¡œë”© ì¤‘ ({FAISS_INDEX_PATH})...")
        if not os.path.isdir(FAISS_INDEX_PATH):
            raise FileNotFoundError(f"FAISS ì¸ë±ìŠ¤ í´ë”({FAISS_INDEX_PATH})ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenAI ì„ë² ë”©ìœ¼ë¡œ ì¸ë±ìŠ¤ë¥¼ ë‹¤ì‹œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.")
        try:
            vectorstore = FAISS.load_local(
                FAISS_INDEX_PATH,
                embeddings, # OpenAIEmbeddings ê°ì²´ ì „ë‹¬
                allow_dangerous_deserialization=True
            )
            print(f"FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ ({vectorstore.index.ntotal} ë²¡í„°).")
            print("   âš ï¸ ê²½ê³ : ë¡œë“œëœ FAISS ì¸ë±ìŠ¤ê°€ ë°˜ë“œì‹œ OpenAI ì„ë² ë”© ëª¨ë¸ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”!")
        except Exception as faiss_load_e:
             print(f"!! [ì˜¤ë¥˜] FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {faiss_load_e}")
             print("   ì¸ë±ìŠ¤ê°€ ì†ìƒë˜ì—ˆê±°ë‚˜, ì˜ëª»ëœ ì„ë² ë”© ëª¨ë¸ë¡œ ìƒì„±ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
             print("   OpenAI ì„ë² ë”© ëª¨ë¸ë¡œ FAISS ì¸ë±ìŠ¤ë¥¼ ë‹¤ì‹œ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.")
             raise faiss_load_e # ì´ˆê¸°í™” ì¤‘ë‹¨

        # ==========================

        # 2.5 BM25ìš© ë°ì´í„° ë¡œë“œ (ê¸°ì¡´ê³¼ ë™ì¼)
        print(f"BM25ìš© ë°ì´í„° ë¡œë”© ì¤‘ ({BM25_DATA_PATH})...")
        if not os.path.exists(BM25_DATA_PATH):
             print(f"âš ï¸ ê²½ê³ : BM25 ë°ì´í„° íŒŒì¼({BM25_DATA_PATH}) ì—†ìŒ. FAISSë§Œ ì‚¬ìš©.")
             split_texts = None
        else:
             try:
                 with open(BM25_DATA_PATH, 'rb') as f:
                     split_texts = pickle.load(f)
                 print(f"BM25ìš© ë°ì´í„° ë¡œë“œ ì™„ë£Œ ({len(split_texts)}ê°œ ì²­í¬).")
             except Exception as e_pickle:
                 print(f"!! [ì˜¤ë¥˜] BM25 ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e_pickle}")
                 split_texts = None

        # 3. Retriever ì„¤ì • (í•˜ì´ë¸Œë¦¬ë“œ ì ìš© - ê¸°ì¡´ê³¼ ë™ì¼)
        print("Retriever ì„¤ì • ì¤‘...")
        if vectorstore:
            faiss_retriever = vectorstore.as_retriever(search_kwargs={'k': FAISS_K})
            print(f"- Dense Retriever (FAISS) ì„¤ì • ì™„ë£Œ (k={FAISS_K}).")
            if split_texts:
                try:
                    bm25_retriever = BM25Retriever.from_documents(split_texts)
                    bm25_retriever.k = BM25_K
                    print(f"- Sparse Retriever (BM25) ì„¤ì • ì™„ë£Œ (k={BM25_K}).")
                    ensemble_retriever = EnsembleRetriever(
                        retrievers=[bm25_retriever, faiss_retriever],
                        weights=ENSEMBLE_WEIGHTS
                    )
                    retriever = ensemble_retriever
                    print(f"- Ensemble Retriever ì„¤ì • ì™„ë£Œ (Weights: BM25={ENSEMBLE_WEIGHTS[0]}, FAISS={ENSEMBLE_WEIGHTS[1]}).")
                except Exception as e_ensemble:
                    print(f"!! BM25/Ensemble ì„¤ì • ì‹¤íŒ¨: {e_ensemble}. FAISS Retrieverë§Œ ì‚¬ìš©.")
                    retriever = faiss_retriever
            else:
                print("âš ï¸ BM25 ë°ì´í„° ì—†ì–´ Dense Retriever(FAISS)ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                retriever = faiss_retriever
        else:
            raise ValueError("FAISS VectorStore ë¡œë“œ ì‹¤íŒ¨. Retriever ì„¤ì • ë¶ˆê°€.")

        # 4. LLM ë¡œë“œ (OpenAI - ê¸°ì¡´ê³¼ ë™ì¼)
        print(f"LLM ë¡œë”© ì¤‘ ({LLM_MODEL_NAME})...")
        llm = ChatOpenAI(model_name=LLM_MODEL_NAME, temperature=0.1, openai_api_key=openai_api_key)
        print("LLM ë¡œë“œ ì™„ë£Œ.")

        # 5. RAG Chain êµ¬ì¶• (ê¸°ì¡´ê³¼ ë™ì¼)
        print("RAG Chain êµ¬ì¶• ì¤‘...")
        template = """ì£¼ì–´ì§„ 'ì»¨í…ìŠ¤íŠ¸' ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ 'ì§ˆë¬¸'ì— ë‹µë³€í•˜ì‹­ì‹œì˜¤. í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
        ì»¨í…ìŠ¤íŠ¸ì— ë‹µë³€ì´ ì—†ìœ¼ë©´ "ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ë§Œìœ¼ë¡œëŠ” ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ë‹µë³€í•˜ì„¸ìš”.
        ì»¨í…ìŠ¤íŠ¸: {context}
        ì§ˆë¬¸: {question}
        ë‹µë³€:"""
        QA_CHAIN_PROMPT = PromptTemplate.from_template(template)

        if not retriever: raise ValueError("Retriever ê°ì²´ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        if not llm: raise ValueError("LLM ê°ì²´ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        global qa_chain # ì „ì—­ ë³€ìˆ˜ í• ë‹¹ ëª…ì‹œ
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True,
            chain_type_kwargs={"prompt": QA_CHAIN_PROMPT}
        )
        is_initialized = True
        print("[ì„±ê³µ] RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ.")

    except Exception as e:
        print(f"!! [ì˜¤ë¥˜] RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        qa_chain = None
        is_initialized = False

# --- âœ… Firebase ë¦¬ìŠ¤ë„ˆ ì½œë°± í•¨ìˆ˜ ---
def firebase_listener_callback(event):
    print(f"\n--- Firebase ì´ë²¤íŠ¸ ê°ì§€ ---")
    print(f"  ì´ë²¤íŠ¸ íƒ€ì…: {event.event_type}, ê²½ë¡œ: {event.path}")

    # ì—¬ëŸ¬ ì§ˆë¬¸ (ì´ˆê¸° ì „ì²´ ë¡œë”© ì‹œ ë°œìƒ)
    if event.path == "/" and isinstance(event.data, dict):
        print("ğŸ“¦ ë£¨íŠ¸ì—ì„œ ì—¬ëŸ¬ ì§ˆë¬¸ì„ ë™ì‹œì— ê°ì§€í•¨.")
        for question_id, question_data in event.data.items():
            if isinstance(question_data, dict) and "query" in question_data:
                handle_single_question(question_id, question_data)
        return

    # ë‹¨ì¼ ì§ˆë¬¸ ê°ì§€
    if event.event_type == 'put' and event.data:
        if isinstance(event.data, dict) and "query" in event.data:
            question_id = event.path.strip("/").split("/")[-1]
            handle_single_question(question_id, event.data)
            return

    print(f"âš ï¸ ë¬´ì‹œëœ ì´ë²¤íŠ¸ ë˜ëŠ” query ì—†ìŒ: {event.path}, ë°ì´í„°: {event.data}")

def handle_single_question(question_id, question_data):
    global qa_chain, processed_question_ids

    question_time = question_data.get("timestamp", 0)
    if question_id in processed_question_ids:
        print(f"âš ï¸ ì´ë¯¸ ì²˜ë¦¬ëœ ì§ˆë¬¸: {question_id} â†’ ìŠ¤í‚µí•¨")
        return

    query = question_data.get("query", "").strip()
    if not query:
        print(f"âš ï¸ ì§ˆë¬¸ ë‚´ìš©ì´ ë¹„ì–´ìˆìŒ: {question_id}")
        return

    try:
        print(f"  âœ… ìœ íš¨í•œ ì§ˆë¬¸ ê°ì§€ë¨: {query} (ID: {question_id})")
        print("  RAG ë‹µë³€ ìƒì„± ì‹œë„...")
        start_time = time.time()
        result = qa_chain.invoke({"query": query})
        end_time = time.time()
        answer = result.get("result", "ì˜¤ë¥˜: ë‹µë³€ ìƒì„± ì‹¤íŒ¨")
        print(f"  ë‹µë³€ ìƒì„± ì™„ë£Œ ({end_time - start_time:.2f}ì´ˆ). ë‹µë³€: {answer[:50]}...")

        source_info = []
        source_documents = result.get("source_documents", [])
        if source_documents:
            source_info = [
                {"content": doc.page_content[:100]+"...", "metadata": {k: str(v)[:50] for k, v in doc.metadata.items()}}
                for doc in source_documents[:2]
            ]

        db.reference(f"{FIREBASE_ANSWERS_PATH}/{question_id}").set({
            "answer": answer,
            "timestamp": int(time.time()),
            "sources": source_info,
        })
        print(f"  Firebase '{FIREBASE_ANSWERS_PATH}/{question_id}' ê²½ë¡œì— ë‹µë³€ ì €ì¥ ì™„ë£Œ.")

        save_processed_id(question_id)  # âœ… ì—¬ê¸°ì„œ ì €ì¥í•´ì•¼ ì§„ì§œ "ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ ì§ˆë¬¸"ì„
        log_question_answer_pair(question_id, query, answer)  # âœ… ì§ˆë¬¸ë‹µë³€ json ì €ì¥

    except Exception as e:
        print(f"!! RAG ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        try:
            db.reference(f"{FIREBASE_ANSWERS_PATH}/{question_id}").set({
                "error": f"{type(e).__name__}: {str(e)[:200]}",
                "timestamp": int(time.time())
            })
        except Exception as db_err:
            print(f"!! Firebase ì˜¤ë¥˜ ê¸°ë¡ ì‹¤íŒ¨: {db_err}")

# === FastAPI ì‹œì‘ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ ===
@app.on_event("startup")
async def startup_event_handler():
    global firebase_app
    print("--- FastAPI Application Startup ---")
    load_processed_ids()  # ğŸ”¥ ì´ ì¤„ ì¶”ê°€

    initialize_rag() # RAG íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ë¨¼ì € ì‹œë„

    if not FIREBASE_DB_URL: print("!! [ì¹˜ëª…ì  ì˜¤ë¥˜] FIREBASE_DATABASE_URL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Firebase ë¦¬ìŠ¤ë„ˆ ì‹œì‘ ë¶ˆê°€."); return
    if not os.path.exists(FIREBASE_SERVICE_ACCOUNT_KEY): print(f"!! [ì¹˜ëª…ì  ì˜¤ë¥˜] Firebase ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼({FIREBASE_SERVICE_ACCOUNT_KEY})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Firebase ë¦¬ìŠ¤ë„ˆ ì‹œì‘ ë¶ˆê°€."); return

    try:
        cred = credentials.Certificate(FIREBASE_SERVICE_ACCOUNT_KEY)
        if not firebase_admin._apps:
             firebase_app = firebase_admin.initialize_app(cred, {'databaseURL': FIREBASE_DB_URL})
             print("[ì„±ê³µ] Firebase Admin SDK ì´ˆê¸°í™” ì™„ë£Œ.")
        else:
             firebase_app = firebase_admin.get_app()
             print("[ì •ë³´] Firebase Admin SDK ì´ë¯¸ ì´ˆê¸°í™”ë¨.")

        print(f"Firebase ê²½ë¡œ '{FIREBASE_QUESTIONS_PATH}' ë¦¬ìŠ¤ë‹ ì‹œì‘...")
        listener_thread = threading.Thread(
            target=db.reference(FIREBASE_QUESTIONS_PATH).listen,
            args=(firebase_listener_callback,),
            daemon=True
        )
        listener_thread.start()
        print("[ì •ë³´] Firebase ë¦¬ìŠ¤ë„ˆ ìŠ¤ë ˆë“œ ì‹œì‘ë¨.")

    except Exception as e:
        print(f"!! [ì˜¤ë¥˜] Firebase ì´ˆê¸°í™” ë˜ëŠ” ë¦¬ìŠ¤ë„ˆ ì‹œì‘ ì‹¤íŒ¨: {e}")
        traceback.print_exc()

# === ê¸°ë³¸ ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ ===
@app.get("/")
async def read_root():
    return {"message": "Nomu RAG Backend is running!", "initialized": is_initialized}

# === ë¡œì»¬ ì‹¤í–‰ìš© ì½”ë“œ ===
if __name__ == "__main__":
    print("--- ë¡œì»¬ ì„œë²„ ì‹œì‘ (uvicorn) ---")
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)